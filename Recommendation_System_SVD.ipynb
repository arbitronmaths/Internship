{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfe81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation System using Collaborative Filtering (SVD)\n",
    "\n",
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore the Dataset\n",
    "# Load MovieLens 100K dataset\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(url, sep='\\t', names=columns)\n",
    "\n",
    "# Display dataset overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.head())\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for Surprise Library\n",
    "# Define reader to normalize ratings between 1 and 5\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load data into Surprise dataset\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a72c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Matrix Factorization (SVD)\n",
    "# Initialize SVD model\n",
    "model = SVD()\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainset)\n",
    "\n",
    "# Test the model\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628182d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "# Calculate MAE\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Display Evaluation Metrics\n",
    "print(f\"\\nEvaluation Metrics:\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f77359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Recommendations\n",
    "# Function to recommend items for a given user\n",
    "def get_recommendations(user_id, model, data, top_n=5):\n",
    "    # Get all item IDs\n",
    "    all_items = data.df['item_id'].unique()\n",
    "\n",
    "    # Get items already rated by the user\n",
    "    rated_items = data.df[data.df['user_id'] == user_id]['item_id']\n",
    "\n",
    "    # Filter unrated items\n",
    "    unrated_items = [item for item in all_items if item not in rated_items]\n",
    "\n",
    "    # Predict ratings for unrated items\n",
    "    predictions = [model.predict(user_id, item) for item in unrated_items]\n",
    "\n",
    "    # Sort predictions by estimated rating\n",
    "    recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Return top N recommendations\n",
    "    return recommendations[:top_n]\n",
    "\n",
    "# Example usage\n",
    "user_id = 1  # Specify a user ID\n",
    "recommendations = get_recommendations(user_id, model, data)\n",
    "print(\"\\nTop Recommendations:\")\n",
    "for rec in recommendations:\n",
    "    print(f\"Item ID: {rec.iid}, Estimated Rating: {rec.est:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# Plot actual vs. predicted ratings\n",
    "actual = [pred.r_ui for pred in predictions]\n",
    "predicted = [pred.est for pred in predictions]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual, predicted, alpha=0.5)\n",
    "plt.plot([1, 5], [1, 5], '--', color='red', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Ratings')\n",
    "plt.ylabel('Predicted Ratings')\n",
    "plt.title('Actual vs. Predicted Ratings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}